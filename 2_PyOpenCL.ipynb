{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "0.0\n",
      "Temp de traitement : 1.0935630798339844\n",
      "Work Item : [  0.00000000e+00   1.00000000e+00   2.00000000e+00 ...,   4.99970000e+04\n",
      "   4.99980000e+04   4.99990000e+04]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import absolute_import, print_function\n",
    "import numpy as np\n",
    "import pyopencl as cl\n",
    "from time import time\n",
    "\n",
    "\n",
    "a_np = np.random.rand(50000).astype(np.float32)\n",
    "b_np = np.random.rand(50000).astype(np.float32)\n",
    "\n",
    "ctx = cl.create_some_context()\n",
    "queue = cl.CommandQueue(ctx)\n",
    "\n",
    "mf = cl.mem_flags\n",
    "a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
    "b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
    "\n",
    "prg = cl.Program(ctx, \"\"\"\n",
    "__kernel void sum(\n",
    "    __global const float *a_g, __global const float *b_g, __global float *res_g, __global float *work_item)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  work_item[gid] = get_global_id(0);\n",
    "  res_g[gid] = a_g[gid] + b_g[gid];\n",
    "}\n",
    "\"\"\").build()\n",
    "\n",
    "res_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
    "work_item_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
    "\n",
    "\n",
    "start = time()\n",
    "prg.sum(queue, a_np.shape, None, a_g, b_g, res_g, work_item_g)\n",
    "\n",
    "res_np = np.empty_like(a_np)\n",
    "work_item = np.empty_like(a_np)\n",
    "\n",
    "cl.enqueue_copy(queue, res_np, res_g)\n",
    "cl.enqueue_copy(queue, work_item, work_item_g)\n",
    "\n",
    "# Check on CPU with Numpy:\n",
    "print(res_np - (a_np + b_np))\n",
    "\n",
    "print(np.linalg.norm(res_np - (a_np + b_np)))\n",
    "\n",
    "print(\"Temp de traitement : \"+str(time()-start))\n",
    "\n",
    "print(\"Work Item : \"+str(work_item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of test without OpenCL:  0.08559370040893555 s\n",
      "===============================================================\n",
      "Platform name: Portable Computing Language\n",
      "Platform profile: FULL_PROFILE\n",
      "Platform vendor: The pocl project\n",
      "Platform version: OpenCL 2.0 pocl 0.13, LLVM 3.8.0\n",
      "---------------------------------------------------------------\n",
      "Device name: pthread-Intel(R) Xeon(R) CPU E3-1240 v5 @ 3.50GHz\n",
      "Device memory:  1515 MB\n",
      "Device max clock speed: 4294 MHz\n",
      "Device compute units: 3\n",
      "Device max work group size: 4096\n",
      "Device max work item sizes: [4096, 4096, 4096]\n",
      "Data points: 8388608\n",
      "Workers: 256\n",
      "Preferred work group size multiple: 8\n",
      "Execution time of test: 0.0235249 s\n",
      "Results doesn't match!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:93: DeprecationWarning: 'enqueue_read_buffer' has been deprecated in version 2011.1. Please use enqueue_copy() instead.\n"
     ]
    }
   ],
   "source": [
    "# example provided by Roger Pau Monn'e\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import pyopencl as cl\n",
    "import numpy\n",
    "import numpy.linalg as la\n",
    "import datetime\n",
    "from time import time\n",
    "\n",
    "data_points = 2**23 # ~8 million data points, ~32 MB data\n",
    "workers = 2**8 # 256 workers, play with this to see performance differences\n",
    "               # eg: 2**0 => 1 worker will be non-parallel execution on gpu\n",
    "               # data points must be a multiple of workers\n",
    "\n",
    "a = numpy.random.rand(data_points).astype(numpy.float32)\n",
    "b = numpy.random.rand(data_points).astype(numpy.float32)\n",
    "c_result = numpy.empty_like(a)\n",
    "\n",
    "# Speed in normal CPU usage\n",
    "time1 = time()\n",
    "c_temp = (a+b) # adds each element in a to its corresponding element in b\n",
    "c_temp = c_temp * c_temp # element-wise multiplication\n",
    "c_result = c_temp * (a/2.0) # element-wise half a and multiply\n",
    "time2 = time()\n",
    "\n",
    "print(\"Execution time of test without OpenCL: \", time2 - time1, \"s\")\n",
    "\n",
    "\n",
    "for platform in cl.get_platforms():\n",
    "    for device in platform.get_devices():\n",
    "        print(\"===============================================================\")\n",
    "        print(\"Platform name:\", platform.name)\n",
    "        print(\"Platform profile:\", platform.profile)\n",
    "        print(\"Platform vendor:\", platform.vendor)\n",
    "        print(\"Platform version:\", platform.version)\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        print(\"Device name:\", device.name)\n",
    "        #print(\"Device type:\", cl.device_type.to_string(device.type))\n",
    "        print(\"Device memory: \", device.global_mem_size//1024//1024, 'MB')\n",
    "        print(\"Device max clock speed:\", device.max_clock_frequency, 'MHz')\n",
    "        print(\"Device compute units:\", device.max_compute_units)\n",
    "        print(\"Device max work group size:\", device.max_work_group_size)\n",
    "        print(\"Device max work item sizes:\", device.max_work_item_sizes)\n",
    "\n",
    "        # Simnple speed test\n",
    "        ctx = cl.Context([device])\n",
    "        queue = cl.CommandQueue(ctx, \n",
    "                properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
    "\n",
    "        mf = cl.mem_flags\n",
    "        a_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a)\n",
    "        b_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b)\n",
    "        dest_buf = cl.Buffer(ctx, mf.WRITE_ONLY, b.nbytes)\n",
    "\n",
    "        prg = cl.Program(ctx, \"\"\"\n",
    "            __kernel void sum(__global const float *a,\n",
    "            __global const float *b, __global float *c)\n",
    "            {\n",
    "                        int gid = get_global_id(0);\n",
    "                        float a_temp;\n",
    "                        float b_temp;\n",
    "                        float c_temp;\n",
    "                        a_temp = a[gid]; // my a element (by global ref)\n",
    "                        b_temp = b[gid]; // my b element (by global ref)\n",
    "                        \n",
    "                        c_temp = a_temp+b_temp; // sum of my elements\n",
    "                        c_temp = c_temp * c_temp; // product of sums\n",
    "                        c_temp = c_temp * (a_temp/2.0f); // times 1/2 my a\n",
    "                        c[gid] = c_temp; // store result in global memory\n",
    "                }\n",
    "                \"\"\").build()\n",
    "\n",
    "        global_size=(data_points,)\n",
    "        local_size=(workers,)\n",
    "        preferred_multiple = cl.Kernel(prg, 'sum').get_work_group_info( \\\n",
    "            cl.kernel_work_group_info.PREFERRED_WORK_GROUP_SIZE_MULTIPLE, \\\n",
    "            device)\n",
    "\n",
    "        print(\"Data points:\", data_points)\n",
    "        print(\"Workers:\", workers)\n",
    "        print(\"Preferred work group size multiple:\", preferred_multiple)\n",
    "\n",
    "        if (workers % preferred_multiple):\n",
    "            print(\"Number of workers not a preferred multiple (%d*N).\" \\\n",
    "                    % (preferred_multiple))\n",
    "            print(\"Performance may be reduced.\")\n",
    "\n",
    "        exec_evt = prg.sum(queue, global_size, local_size, a_buf, b_buf, dest_buf)\n",
    "        exec_evt.wait()\n",
    "        elapsed = 1e-9*(exec_evt.profile.end - exec_evt.profile.start)\n",
    "\n",
    "        print(\"Execution time of test: %g s\" % elapsed)\n",
    "\n",
    "        c = numpy.empty_like(a)\n",
    "        cl.enqueue_read_buffer(queue, dest_buf, c).wait()\n",
    "        equal = numpy.all( c == c_result)\n",
    "\n",
    "        if not equal:\n",
    "                print(\"Results doesn't match!!\")\n",
    "        else:\n",
    "            print(\"Results OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.get_cl_header_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " a_np : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      " b_np : [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " res_np : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49]\n",
      "\n",
      " Temp de traitement : 0.0038101673126220703\n",
      "----------------------------------------------\n",
      "get_global_size(0) [Nombre de thread] : 50\n",
      "get_global_size(1) : 1\n",
      "get_local_size(0) : 1\n",
      "get_local_size(1) : 1\n",
      "get_local_id(0) : 0\n",
      "get_local_id(1) : 0\n",
      "get_global_id(0) : 15\n",
      "get_global_id(1) : 0\n",
      "get_work_dim() : 1\n",
      "get_num_groups(0) [Nombre de Work Group-(Coeur 0)] : 50\n",
      "get_num_groups(1) [Nombre de Work Group-(Coeur 1)] : 1\n",
      "get_group_id(0) : 15\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import absolute_import, print_function\n",
    "import numpy as np\n",
    "import pyopencl as cl\n",
    "from time import time\n",
    "\n",
    "\n",
    "a_np = np.zeros(50).astype(np.int)\n",
    "b_np = np.ones(50).astype(np.int)\n",
    "\n",
    "info_np = np.zeros(10).astype(np.int)\n",
    "\n",
    "ctx = cl.create_some_context()\n",
    "queue = cl.CommandQueue(ctx)\n",
    "\n",
    "mf = cl.mem_flags\n",
    "a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
    "b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
    "\n",
    "prg = cl.Program(ctx, \"\"\"\n",
    "__kernel void sum(\n",
    "    __global const int *a_g, __global int *b_g, __global int *res_g, __global int *info)\n",
    "{\n",
    "  int gid = get_global_id(0);\n",
    "  \n",
    "  info[0] = get_global_size(0);\n",
    "  info[1]  = get_global_size(1);\n",
    "  info[2] = get_local_size(0);\n",
    "  info[3]  = get_local_size(1);\n",
    "  info[4]  = get_local_id(0);\n",
    "  info[5]  = get_local_id(1);\n",
    "  info[6]  = get_global_id(0);\n",
    "  info[7]  = get_global_id(1);\n",
    "  info[8]  = get_work_dim();\n",
    "  info[9]  = get_num_groups(0);\n",
    "  info[10]  = get_num_groups(1);\n",
    "  info[11]  = get_group_id(0);\n",
    "  \n",
    "  \n",
    "  //for (y=get_global_id(0); y<25; y+=get_global_size(0)){\n",
    "      //info[11] = info[11]+1;\n",
    "  //}\n",
    "  //res_g[gid] = a_g[gid] + get_global_id(0);\n",
    "    res_g[gid] = a_g[gid] + get_group_id(0);\n",
    "}\n",
    "\"\"\").build()\n",
    "\n",
    "res_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
    "info_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
    "\n",
    "\n",
    "start = time()\n",
    "prg.sum(queue, a_np.shape, None, a_g, b_g, res_g, info_g)\n",
    "\n",
    "res_np = np.empty_like(a_np)\n",
    "info = np.empty_like(a_np)\n",
    "\n",
    "\n",
    "cl.enqueue_copy(queue, res_np, res_g)\n",
    "cl.enqueue_copy(queue, info, info_g)\n",
    "\n",
    "        \n",
    "# Check on CPU with Numpy:\n",
    "print(\"\\n a_np : \"+str(a_np))\n",
    "\n",
    "print(\"\\n b_np : \"+str(b_np))\n",
    "\n",
    "print(\"\\n res_np : \"+str(res_np))\n",
    "\n",
    "print(\"\\n Temp de traitement : \"+str(time()-start))\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"get_global_size(0) [Nombre de thread] : \"+str(info[0]))\n",
    "print(\"get_global_size(1) : \"+str(info[1]) )\n",
    "print(\"get_local_size(0) : \"+str(info[2]) )\n",
    "print(\"get_local_size(1) : \"+str(info[3]) )\n",
    "print(\"get_local_id(0) : \"+str(info[4]) )\n",
    "print(\"get_local_id(1) : \"+str(info[5]) )\n",
    "print(\"get_global_id(0) [] : \"+str(info[6] ) )\n",
    "print(\"get_global_id(1) : \"+str(info[7]))\n",
    "print(\"get_work_dim() : \"+str(info[8]))\n",
    "print(\"get_num_groups(0) [Nombre de Work Group-(Coeur 0)] : \" +str(info[9]))\n",
    "print(\"get_num_groups(1) [Nombre de Work Group-(Coeur 1)] : \" +str(info[10]))\n",
    "print(\"get_group_id(0) : \" +str(info[11]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import pyopencl as cl\n",
    "kcode = \"\"\"kernel void test() { printf(\"Hello from DSP (%d)\\\\n\", get_group_id(0)); }\"\"\"\n",
    "ctx   = cl.create_some_context()\n",
    "Q     = cl.CommandQueue(ctx)\n",
    "prg   = cl.Program(ctx, kcode).build(options=\"\")\n",
    "prg.test(Q, [8], [1]).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
